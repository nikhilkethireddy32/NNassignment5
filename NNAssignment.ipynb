{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "from google.colab import drive\ndrive.mount('/content/gdrive')\n#glass dataset\npath_to_csv = '/content/gdrive/My Drive/glass.csv'\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i92FSRn0cry",
        "outputId": "2be80c2f-7a3f-4274-af61-d4424ae1790f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707784742207,
          "user_tz": 360,
          "elapsed": 1191,
          "user": {
            "displayName": "Hemanth Kumar Suddala",
            "userId": "17917981146547440067"
          }
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'ModuleNotFoundError'>",
          "evalue": "No module named 'google.colab'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/gdrive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#glass dataset\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\n# Read the provided CSV file ‘data.csv’\ndata = pd.read_csv(path_to_csv)\ndata",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "oOWStWwb0hiP",
        "outputId": "35c44ec9-e24b-4318-b09e-93751a51d647",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707784746080,
          "user_tz": 360,
          "elapsed": 175,
          "user": {
            "displayName": "Hemanth Kumar Suddala",
            "userId": "17917981146547440067"
          }
        },
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'path_to_csv' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Read the provided CSV file ‘data.csv’\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[43mpath_to_csv\u001b[49m)\n\u001b[1;32m      4\u001b[0m data\n",
            "\u001b[0;31mNameError\u001b[0m: name 'path_to_csv' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "# import libraries for Naive Bayes and SVM\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\n\n#spliting data in training and testing part\nX=data.drop('Type',axis=1)\ny=data['Type']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 0)\n\n\n\n\n",
      "metadata": {
        "id": "yxnO_KV20j-G",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707784757141,
          "user_tz": 360,
          "elapsed": 173,
          "user": {
            "displayName": "Hemanth Kumar Suddala",
            "userId": "17917981146547440067"
          }
        }
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "#Implement Naïve Bayes method using the scikit-learn library\n#create an instance Of gaussian classifier\nclassifier = GaussianNB()\n\n#Fit the classifier on the training data:\nclassifier.fit(X_train, y_train)\n\n#use the trained classifier to predict the labels for the testing data using :\ny_pred = classifier.predict(X_test)\n# Evaluate the model on testing part using score and clasification_report\nprint(classification_report(y_test, y_pred))\nprint(confusion_matrix(y_test, y_pred))\nprint('accuracy is',accuracy_score(y_pred,y_test))",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBYspDbK08Np",
        "outputId": "3c087210-7dde-4dfc-9712-62c6f91159c3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707784775575,
          "user_tz": 360,
          "elapsed": 155,
          "user": {
            "displayName": "Hemanth Kumar Suddala",
            "userId": "17917981146547440067"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.33      0.04      0.06        28\n",
            "           2       0.56      0.15      0.24        33\n",
            "           3       0.16      0.73      0.26        11\n",
            "           5       0.20      0.50      0.29         2\n",
            "           6       0.43      1.00      0.60         3\n",
            "           7       0.82      1.00      0.90         9\n",
            "\n",
            "    accuracy                           0.31        86\n",
            "   macro avg       0.42      0.57      0.39        86\n",
            "weighted avg       0.45      0.31      0.27        86\n",
            "\n",
            "[[ 1  3 22  0  1  1]\n",
            " [ 0  5 21  4  3  0]\n",
            " [ 2  1  8  0  0  0]\n",
            " [ 0  0  0  1  0  1]\n",
            " [ 0  0  0  0  3  0]\n",
            " [ 0  0  0  0  0  9]]\n",
            "accuracy is 0.313953488372093\n"
          ]
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": "#Implement SVM\n#Create an instance of the SVC classifier\nclassifier=svm.SVC()\n#Fit the classifier on the training data:\nclassifier.fit(X_train,y_train)\n#Predict the labels for the testing data:\ny_pred=classifier.predict(X_test)\nprint(classification_report(y_test,y_pred,zero_division=1))\nprint(confusion_matrix(y_test,y_pred))\nprint(\"accuracy is:\", accuracy_score(y_pred,y_test))",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZ-Dwpmc0_qa",
        "outputId": "63f406a2-23e5-4ad6-d24b-6bc72cb54bac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1707784784708,
          "user_tz": 360,
          "elapsed": 143,
          "user": {
            "displayName": "Hemanth Kumar Suddala",
            "userId": "17917981146547440067"
          }
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      0.00      0.00        28\n",
            "           2       0.38      1.00      0.55        33\n",
            "           3       1.00      0.00      0.00        11\n",
            "           5       1.00      0.00      0.00         2\n",
            "           6       1.00      0.00      0.00         3\n",
            "           7       1.00      0.00      0.00         9\n",
            "\n",
            "    accuracy                           0.38        86\n",
            "   macro avg       0.90      0.17      0.09        86\n",
            "weighted avg       0.76      0.38      0.21        86\n",
            "\n",
            "[[ 0 28  0  0  0  0]\n",
            " [ 0 33  0  0  0  0]\n",
            " [ 0 11  0  0  0  0]\n",
            " [ 0  2  0  0  0  0]\n",
            " [ 0  3  0  0  0  0]\n",
            " [ 0  9  0  0  0  0]]\n",
            "accuracy is: 0.38372093023255816\n"
          ]
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "**Which algorithm you got better accuracy? Can you justify why?**\n\nLinear SVM has better Accuracy than the Naive bayes Algorithm, Accuracy can vary depending on the dataset and its inherent characteristics. Generally, Linear SVM tends to perform well when the data has clear linear separability, whereas Naive Bayes is a probabilistic classifier that can work well with simple datasets and when the independence assumption holds (i.e., features are conditionally independent given the class). The Glass dataset have certain characteristics that favor one algorithm over the other. The data has a linear separation between classes, Linear SVM performed better. On the other hand, if the features are conditionally independent given the class, Naïve Bayes might work well. Linear SVM doesn't make strong assumptions about feature independence. But, Naive Bayes assumes that features are conditionally independent given the class, which might not hold true in some real-world datasets. Lastly, Linear SVM can model complex decision boundaries when used with different kernels, such as polynomial or radial basis function (RBF) kernels. Naive Bayes assumes linear boundaries between classes.\n\n\n\n",
      "metadata": {
        "id": "By20tRon1Cv1"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}